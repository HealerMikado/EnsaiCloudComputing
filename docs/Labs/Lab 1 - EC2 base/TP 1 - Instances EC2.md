---
layout: default
title: "TP 1 - D√©couverte d'AWS ‚õÖ"
nav_order: 1
parent: Labs
---



# TP 1 - Instances EC2 , Auto Scaling Group et Load Balancer

## Pr√©ambule

Ce TP √† la forme d'un tutoriel. Il vous suffit de suivre les √©tapes √† votre rythme pour arriver √† la fin. Tout est expliqu√© et il peut √™tre fait en autonomie sans difficult√©. Le but est de vous familiariser avec la plateforme AWS et r√©aliser des t√¢ches simples. Comme vous allez le constater rapidement, AWS n'est pas une plateforme *beginner friendly*. Il y a beaucoup d'√©tapes et de configurations √† r√©aliser pour lancer un service m√™me simple. Pendant le TP mettez vous par groupe de 3-4 pour vous entraider et avancer quand je ne suis pas disponible.

Encore une chose, le TP est s√ªrement trop long √™tre fait sur une s√©ance. Si cela arrive il sera continu√© la s√©ance suivante.

üë©‚Äçüíªüë®‚ÄçüíªHappy coding !

## Connexion √† la console AWS

1. Connectez vous √† la plateforme AWS academy : https://www.awsacademy.com avec les identifiants que vous avez cr√©e et s√©lectionnez le cours AWS Academy Learner Lab [43226].
2. Cliquez sur `Modules` puis `Learner Lab` 
3. Ensuite cliquez sur `Start Lab`. Une fois le lab lanc√© (pastille verte √† gauche), cliquez sur `AWS Details` et `Download PEM`. Cela va t√©l√©charger la cl√© priv√© qui permettra d'√©tablir des connexions SSH pendant le TP.
4. Enfin cliquez sur `AWS`

üéâ Vous voil√† connect√©.e √† la console AWS

## Ma premi√®re instance EC2

1. Dans la barre de recherche en haut cherchez `EC2` et cliquez sur le service. Vous arriverez sur une page similaire √† la page ci-dessous : 

   ![](img/EC2-dashboard.png)

2. Cliquez sur `Lancer une instance` pour arriver sur l'√©cran de cr√©ation de votre premi√®re instance EC2.

   - **Nom et balise** : donnez un nom √† votre instance. Ex : Ma premi√®re instance

   - **Images d'applications et de syst√®mes d'exploitation (Amazon Machine Image)** : c'est ici que vous allez choisir le syst√®me d'exploitation de votre machine. Vous allez choisir une machine `Ubuntu` et laisser la version 22.04 s√©lectionn√©e par d√©faut.

   - **Type d'instance** : regardez les diff√©rents types d'instances disponibles. Par d√©faut l'instance t2.micro est s√©lectionn√©e. C'et une petite instance avec 1 vCpu (~1 coeur) et 1Go de Ram qui conviendra parfaitement pour le TP. La famille des instances "t" sont pour un usage g√©n√©ral, et peuvent en cas de besoin se voir allouer plus de CPU (mais le prix augmentera). Mais si vous le souhaitez vous pouvez prendre une t3.xlarge (4vCPU, 16 Go Ram, 0,16\$/h) voir une c6in.xlarge (32 vCPU, 64 Go Ram, 1,8\$/h). Si vous voulez jouer ne prenez pas une machine avec plus de 32 vCPU.

     > üßô‚Äç‚ôÇÔ∏è La taille de la machine ne va pas impacter les performances du TP, vous pouvez laisser le type par d√©faut

   - **Paire de cl√© (connexion)** : s√©lectionnez la clef `vockey`. Ce param√®tre d√©finit quelle cl√© SSH sera reconnue par la machine. Ce param√®tre est obligatoire si l'on souhaite se connecter en SSH √† une instance.

   - **Param√®tres r√©seau** : cette configuration permet de d√©terminer dans quel r√©seau et sous-r√©seau se trouvera votre machine, si elle sera accessible depuis internet et les r√®gles de pare-feu. Par d√©faut votre instance sera plac√© dans le r√©seau de votre compte, dans un sous r√©seau public. Cochez la case `Autoriser le trafic HTTP depuis l'Internet`. Cela va rendre notre webservice accessible depuis internet.

     > üßô‚Äç‚ôÇÔ∏è AWS est une plateforme qui doit permettre √† une √©quipe IT de recr√©er toute une architecture physique dans le cloud. Il y a donc beaucoup de param√®tres qui ne sont pas de la comp√©tence d'un data scientist. En deux mots, tout cela permet de s√©curisez un syst√®me d'information en emp√™chant l'ext√©rieur d'acc√©der √† certaines machines (comme les bases de donn√©es), et de segmentez un gros syst√®me en zones isol√©es pour limiter les risques d'intrusion dans le syst√®me.

   - **Stockage (volumes)** : laissez le param√®tre par d√©faut. Votre machine aura un volume EBS (~un disque dur) de 8Go.

   Une fois cela fait vous pouvez lancer votre instance en cliquant sur `Lancer l'instance`. Apr√®s quelques secondes un √©cran affichant que votre lancement est r√©ussi devrait appara√Ætre. Cliquez sur `Affichez toutes les instances`

3. Une fois sur le dahsboard de vos instances, cliquez sur l'id de votre instance pour arriver sur son dashboard et copiez son `Adresse IPv4 publique`.

4. Vous allez maintenance vous connecter √† votre instance.

   **Ubuntu** : ouvrez le terminal avec un `Ctrl+Alt+T`, puis
   ```
   cd .\T√©l√©chargements
   ssh -i "labsuser.pem" ubuntu@[adresseIPv4]
   ```
   en rempla√ßant `[adresseIPv4]` par l'adresse de votre instance. Tapez `yes` √† la question qui vous sera pos√©e.

   **Windows** : ouvrez un powershell (barre de chercher>powershell) et faites

   ```
   cd .\Downloads
   ssh -i "labsuser.pem" ubuntu@[adresseIPv4]
   ```
   en rempla√ßant `[adresseIPv4]` par l'adresse de votre instance. Tapez `yes` √† la question qui vous sera pos√©e.

   **MacOs** : ouvrez le terminal et allez dans votre dossier contenant votre cl√© t√©l√©chargement. Puis faites
   ```
   ssh -i "labsuser.pem" ubuntu@[adresseIPv4]
   ```

   en rempla√ßant `[adresseIPv4]` par l'adresse de votre instance. Tapez `yes` √† la question qui vous sera pos√©e.

   Votre terminal devra se remplir de texte et terminer par un prompt commen√ßant par `ubuntu@XXXXX`

   üéâF√©licitation vous venez de cr√©er une machine virtuelle et de vous y connecter !

1. Maintenant clonez le d√©p√¥t du TP avec la commande `git clone https://github.com/HealerMikado/Ensai-CloudComputingLab1.git` et installez tous les outils n√©cessaires pour faire fonctionner le webservice :

   - `sudo apt update` : pour mettre √† jouer les d√©p√¥ts de paquets. Cela permet √† votre machine de savoir ce qu'elle peut installer
   - `sudo apt install python3-pip`: pour installer pip. Python est d√©j√† pr√©sent sur la machine mais pas pip
   - `cd Ensai-CloudComputingLab1` : pour vous placer dans le r√©pertoire du webservice
   - `sudo pip3 install -r requirements.txt` : pour installer les d√©pendances python
   - `sudo python3 app.py` : pour lancer finalement le webservice

   > üßô‚Äç‚ôÇÔ∏è`sudo` permet de lancer une commande en mode "super utilisateur"  ou "root" (= administrateur dans le monde windows). Les commandes de type `apt` sont toujours lanc√©es en root. Pour les commandes `pip3` et `python` ce n'est pas syst√©matiquement le cas, mais dans le cadre de l'exercice comme notre webservice va √™tre accessible depuis tout internet, il nous faut lancer le code en root, et √©galement installer les packages python en root.

   Ouvrez un navigateur web ou Insomnia sur votre ordinateur et faite une requ√™te √† la page `http://[adresseIPv4]/task` en rempla√ßant `[adresseIPv4]` par l'adresse IPv4 de votre instance. Vous devrez arriver sur une page contenant 3 √©l√©ments.

2. Maintenant vous allez √©teindre votre instance. Sur la page de l'instance faites `Etat de l'instance` > `Arr√™ter l'instance`. Attendez quelques instants et rafraichissez la page. Normalement elle devrait avoir comme √©tat `Arr√™t√©(e)` et ne plus avoir de `DNS IPv4 Public`. V√©rifiez que votre webservice n'est plus accessible.

3. Relancez votre instance avec `Etat de l'instance` > `D√©marrer l'instance`. Regardez les adresses publiques de votre instance, elle devrait avoir chang√© ! Connectez vous √† votre instance comme pr√©c√©demment mais en faisant attention d'utiliser la nouvelle adresse. Une fois connectez √† l'instance faite un `ls` (listing) pour voir que le dossier du webservice est toujours pr√©sent, puis un `cd Ensai-CloudComputingLab1` pour vous placer dans le dossier. Comme l'instance a √©t√© √©teinte il faut relancer le webservice, mais comme toutes les d√©pendances ont √©t√© install√©es, il suffit de faire `sudo python3 app.py`. Acc√©dez √† votre webservice en utilisant la nouvelle adresse publique de votre machine.

4. Maintenant vous allez simplement red√©marrer votre machine via l'option `Red√©marrez une instance`. Le red√©marrage va √™tre quasiment instantan√©, et il n'y aura aucun gros changement dans le dashboard. Il vous faut n√©anmoins relancer votre webservice qui a √©t√© √©teint dans le processus. 

   > üßô‚Äç‚ôÇÔ∏è Quand vous √©teignez votre machine, AWS va r√©cup√©rer les ressources associ√©es, et quand vous allez la relancer AWS va red√©ployer votre machine, mais potentiellement sur un autre serveur. Voici pourquoi son adresse publique a chang√©. Par contre quand vous red√©marrez une machine, AWS fait un simple reboot, sans jamais r√©cup√©rer les ressources. C'est pour cela que c'est plus rapide, et que l'adresse publique reste la m√™me.

5. Votre machine ne sera plus utile alors r√©siliez l√†. La r√©siliation consiste √† supprimer totalement une machine. C'est une action destructive, qui peut entra√Æner une perte de donn√©es.

## Ma premi√®re flotte d'instances

Le but de cette partie est de g√©rer une flotte d'instance via un *Auto Scaling Group* et de rendre accessible cette flotte via un point d'entr√©e unique qui s'appelle un *Load Balancer*. Le *Load Balancer* va r√©partir la charge entre les diff√©rentes machines pour √©viter de surcharger une machine en particulier. Voici architecture que vous allez b√¢tir : 

<img src="img/ELB+ASG.jpg" style="zoom:67%;" />

1. Sur le panneau de gauche cliquez sur `Mod√®les de lancement ` dans la rubrique `Instances`. Une fois sur la page des mod√®les cliquez sur `Cr√©er un mod√®le de lancement`.

2. La page de cr√©ation de mod√®le est extr√™mement similaire √† celle de la cr√©ation d'une instance. Mais cette fois-ci vous allez seulement cr√©er un plan qui permettra de cr√©er des instances toutes identiques.
   - **Nom du mod√®le** : modele-webservice
   - **Images d'applications et de syst√®mes d'exploitation (Amazon Machine Image)** : cliquez sur d√©marrage rapide, puis ubuntu.
   - **Type d'instance** : prenez une t2.micro pour cet exercice.

   - **Paire de cl√© (connexion)** : s√©lectionnez la clef `vockey`. 

   - **Param√®tres r√©seau** : laissez le param√®tre du sous r√©seau par d√©faut. Il signifie que ce mod√®le ne fixe pas le sous r√©seau √† utiliser. Pour le pare-feu s√©lectionn√© le `lauch-wizard-1` qui correspond √† celui qui a √©t√© cr√©e lors de la premi√®re partie du TP.

   - **Stockage (volumes)** : laissez le param√®tre par d√©faut. Votre machine aura un volume EBS (~un disque dur) de 8Go.

   - **D√©tails avanc√©s** : allez au bas de la page jusqu'√† l'option `Donn√©es utilisateur`. Saisissez le texte suivant

        ```bash
        #!/bin/bash
        apt update
        apt install -y python3-pip
        git clone https://github.com/HealerMikado/Ensai-CloudComputingLab1.git
        cd Ensai-CloudComputingLab1
        pip3 install -r requirements.txt
        python3 app.py
        ```
        
        Ce sont les m√™mes commandes que vous avez fait pr√©c√©demment, mais sans le sudo car par d√©faut le script de lancement est ex√©cut√© en super user.

   Validez la cr√©ation de votre mod√®le. 

3. Une fois votre mod√®le cr√©√©, dans le menu de gauche cherchez `Groupe Auto Scaling` (c'est la derni√®re option) puis une fois sur la page des *Auto Scaling Group* cliquez sur `Cr√©er un groupe Auto Scaling`.

   1. Donnez le nom que vous souhaitez √† votre groupe comme `ASG-webservice`. Pour le mod√®le de lancement choisissez le mod√®le que vous venez de cr√©er. `Suivant`

   2. Dans la partie r√©seau, s√©lectionnez au moins 2 sous-r√©seaux, mais vous pouvez tous les prendre si vous le souhaitez. `Suivant`

      > üßô‚Äç‚ôÇÔ∏è Chacun de ces sous r√©seaux est situ√© dans un datacenter diff√©rent. Utiliser au moins 2 sous-r√©seaux assure que si un datacenter tombe nous aurons des machines toujours accessibles. Cela n'arrivera pas pendant le TP mais c'est une chose √† prendre en compte dans le monde professionnel.

   3. S√©lectionnez l'option `Attacher un nouvel √©quilibreur de charge`. Vous pouvez modifier le nom si vous le souhaitez. S√©lectionnez comme sch√©ma de l'√©quilibreur de charge `Internet-Facing`. Dans la partie `Ecouteur de routage`, cliquez sur `S√©lectionner un groupe cible nouveau ou existant` puis sur `Creer un groupe cible`. Cela va associer votre *Auto Scaling Group* au *Load Balancer*. `Suivant`

   4. Pour la taille du groupe saisissez les valeurs suivantes :

      - Capacit√© souhait√©e : 2
      - Capacit√© minimale : 2
      - Capacit√© maximale : 4

      Cliquez sur l'option `Politique de suivi des objectifs et d'√©chelonnement` et laissez la valeur par d√©faut. Nous venons de configurer un groupe d'instance qui va commencer √† 2 instances, et qui pourra avoir entre 2 et 4 instances. Si AWS d√©tecte que l'utilisation globale du CPU d√©passe 50% AWS va cr√©er une nouvelle instance. `Passer √† la v√©rification`

   5. Descendez au bas de la page et `Cr√©er un groupe Auto Scaling`

4. Maintenant votre *Auto Scaling Group* est cr√©√© retournez sur le dashboard des instances EC2. Vous devrez voir que vous avez 2 instances en train de se lancer. Dans un autre onglet, allez sur le dashboard `√âquilibreurs de charge` et trouver votre *Load Balancer*. Cliquez dessus et copiez son `DNS name`. Dans un troisi√®me onglet requ√™tez l'URL `[load balancer DNS name]/instance`. Rafra√Æchissez la page plusieurs fois. Vous devrez constater que l'id retourn√© va osciller entre deux valeurs, les valeurs des instances EC2 de votre dashboard.

5. Sur le dashboard EC2 r√©siliez une instance. Attendez quelques instants (environ 2min), et vous devriez voir qu'automatiquement une nouvelle instance va √™tre d√©marr√©e pour respecter notre r√®gle de 2 instances au minimum.

6. Connectez vous √† une instance et ex√©cutez la commande suivante : `while : ; do : ; done`. Cette commande bloque votre instance et lance une boucle infinie compos√©e de l'instruction null ` :` et saturer le CPU de la machine. Attendez quelques minutes et de nouvelle instance vont √™tre lanc√©es automatiquement pour conserver une globale du CPU √† 50%. Vous pouvez arr√™ter la commande avec un `ctrl+C` et apr√®s une dizaine de minute le nombre d'instance diminuera. Comme la r√©duction de votre flotte prend plus temps, vous aurez du mal √† voir √ßa en TP.

F√©licitation, vous venez en quelques clics de d√©ployer un architecture simple et efficace qui s'adapte √† la charge et hautement disponible car r√©partie sur deux datacenters. L'architecture que vous venez de cr√©er est dites **hautement disponible** et **√©lastique**. En d'autres terme, elle est capable de s'adapter √† la charge aussi bien en augmentant ou en diminuant le nombre de machine (√©lasticit√©), mais aussi elle va continuer √† fonctionner en cas de panne massive (haute disponibilit√©). Il manque encore une base de donn√©es √† notre application pour le moment pour quelle soit r√©ellement int√©ressante. Nous verrons plus tard dans le cours comment associer un code python √† une base de donn√©es h√©berg√©e sur AWS.
