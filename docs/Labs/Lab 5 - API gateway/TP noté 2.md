---
layout: default
title: "TP not√©2 - Faire une API REST 100% serverless üß∞"
nav_exclude: true
---

# Devoir not√© 2 : Postagram

Ce sujet peut para√Ætre imposant et impossible √† terminer mais ce n'est pas le cas. Il ne contient que peu de code √† √©crire (maximum 100 lignes de python, et une infrastructure d√©j√† vue). R√©sultat, avancez pas √† pas, il n'est pas demand√© de le rendre √† la fin du TP. Le rendu final est attendu pour le 14 mai.

## üìÉSujet

Dans ce devoir not√© vous allez concevoir la partie backend du nouveau r√©seau social de partage de photos, **Postagram**. Voici le diagramme d'architecture de l'application.

<img src="img/architecture cible TP not√©.png" style="zoom: 50%;" />

Le service sera h√©berg√© par une flotte d'instances **EC2** (1 par d√©faut, 4 en cas de forte charge) g√©r√©e par un **Auto Scaling Group** derri√®re un Load Balancer. Il sera √©crit en python en utilisant la librairie FastApi et devra r√©pondre √† plusieurs endpoints :

- `POST /posts` pour cr√©er une publication ;
- `DELETE /posts/{id}` pour supprimer une publication ;
- `GET /posts` pour lire toutes les publications stock√©es en base ;
- `GET /posts?user=username` pour lire toutes les publications d'un utilisateur ;
- `GET /getSignedUrlPut` qui retourne une url sign√©e pour pouvoir uploader une image (d√©j√† fourni).

Vous utiliserez en plus :

- Un **bucket S3** pour stocker les images ;
- Une base **DynamoDB** pour stocker les postes ;
- Une **fonction lambda** qui se d√©clenchera √† chaque d√©p√¥t de fichier dans le bucket S3 et appellera le service **Amazon Rekognition** pour d√©tecter les labels et les stocker dans la base DynamoDB.

## üì¶ Attendu 

Votre but n'est pas de r√©aliser l'int√©gralit√© de l'application, mais seulement la partie cr√©ation d'une publication et d√©tection des labels via le service **Amazon Rekognition**, r√©cup√©ration des publications et suppression des publications. Le reste vous est d√©j√† donn√©. Ainsi vous avez √† votre disposition:

- Une application web √©crite en Reactjs (le dossier webapp) qui va communiquer avec votre application. Aucune connaissance en Reactjs n'est attendue, ce code est uniquement l√† pour requ√™ter votre webservice. Vous avez n√©anmoins √† modifier la ligne 12 du fichier index.js pour mettre √† la place l'adresse de votre Load Balancer quand vous testerez votre code sur AWS. Attention l'url ne doit pas avoir de / √† la fin !! Pour lancer cette application placez vous dans le dossier webapp et faites **npm install** la premi√®re fois puis un npm start ensuite. 
- Une base de webservice avec tous les endpoints de d√©finis. Vous allez devoir d√©finir les fonctions vides. Ce web service contient la fonction qui permet de g√©n√©rer une URL pr√©sign√©e pour S3. Ne la touchez pas ! Pour lancer le webservice faites un `python3 app.py`. Le webservice se lance sur le port 8080.
- Une base de projet Terraform √† compl√©ter

Le code est √† r√©cup√©rer avec un `git clone https://github.com/HealerMikado/postagram_ensai.git`

Cet exercice est √† faire par groupe de 3 max. Vous pouvez ainsi le faire seul √† deux ou √† trois. Vous noterez les membres du groupe dans un fichier `groupe.md` m√™me si vous √™tes seul ! Vous rendrez une Moodle une archive .zip contenant tout le code du projet (scripts terraform et le code du webservice). A la diff√©rence de l‚Äôexercice pr√©c√©dent, votre code ne peut pas fonctionner tel quel. Il n'est pas possible d'injecter dans les instances EC2 le nom du bucket et de la table dynamoDB directement. Vous allez ainsi devoir r√©aliser 2 scripts terraform :

- Le premier avec l'architecture *serverless* : bucket S3, lambda et DynamoDB qui devra avoir 2 terraform output avec le bucket S3 g√©n√©r√© et la table dynamoDB
- Le second avec l'architecture avec serveur : EC2, auto scalling group et load balancer. Vous mettrez √† jours les variables `bucket` et `dynamo_table` avec les variables qui proviendront du premier script. Ces variables seront inject√©es comme variables d'environnement dans les instances EC2 pour √™tre accessible avec `os.getenv()`. Pendant la phase de d√©veloppement sur votre machine, mettez √† jour le fichier `.env`

Pour ex√©cuter un fichier sp√©cifique faites, `cdktf deploy -a python mon_script.py`

Si vous faites ce projet en groupe, je vous encourage √† rapidement mettre en place un d√©p√¥t git et √† travailler en parall√®le.

Voici le macro-bar√®me qui sera appliqu√© si vous √™tes 3 :

- Vous avez tout qui fonctionne correctement : 20
- Vous avez les fonctionnalit√©s de base qui fonctionnent sans la g√©n√©ration url sign√©es pour l'affichage des images et la d√©tection des labels : 16
- Vous avez la possibilit√© de poster et afficher des publications : 14
- Vous avez seulement la partie cr√©ation de publication : 10

Je pars du principe que le code python est propre √† chaque fois et que le template Terraform fonctionne. Je n'attends pas des commentaires partout, mais un code lisible (variables signifiantes √† minima).

Si vous faites ce travail seul ou √† deux cela sera pris en compte. Consid√©rez que si vous √™tes seul, faire la fonctionnalit√© de cr√©ation de publications et leur r√©cup√©ration vaudra un 20. Si vous √™tes √† deux le 20 il faut ajouter la partie d√©tection des labels.

## ‚ú® Aides

Ce projet contient des choses que vous avez d√©j√† vu, ainsi que des choses nouvelles. VVoici de nombreux exemples de code pour vous aider. N‚Äôh√©sitez pas √† retourner dans le cours ou √† aller sur Internet. Bien entendu, ce ne sont que des aides, et pas la solution √† l'exercice.

### üí£Comment attaquer le probl√®me

Vous avez trois choses √† faire :

1. Un webservice python qui communique avec divers services AWS

2. Une lambda qui se d√©clenche quand un fichier est d√©pos√© sur S3

3. Le code de l'infra √† d√©ployer

Je vous conseille de faire ce travail dans cet ordre :

1. Cr√©er le code terraform pour cr√©er le bucket s3 et la base dynamoDB
2. Faites la partie cr√©ation de posts et leur r√©cup√©ration
3. Mettez √† jour le code Terraform pour ajouter une lambda qui se d√©clenche quand un fichier est d√©pos√© dans le bucket
4. Impl√©mentez la lambda via l'interface graphique d'AWS
5. R√©cup√©rez le code et mettez votre script Terraform √† jour
6. Finissez le code Terraform pour d√©ployer un webservice python comme dans le TP 2

Faire fonctionner votre code avec l'IHM peut s'av√©rer complexe car l'IHM attend les donn√©es dans le format des posts donn√© ci-dessous. Si vous n'arrivez pas √† faire fonctionner votre code avec l'interface, **ce n'est pas grave** ! Faites le fonctionner avec Insomnia, Postman ou des requ√™tes http en python via `request`.

### üí¨ Les posts

La donn√©e au coeur de votre application est un post. Un post pourra avoir les donn√©es suivantes :

- Un `id` unique (obligatoire). Cet id sera g√©n√©r√© par l'application quand elle recevra un post. Vous aller utiliser la biblioth√®que `uuid` pour √ßa. 

  ```python
  import uuid
  
  str_id = f'{uuid.uuid4()}'
  ```

- Un titre donn√© par l'utilisateur (obligatoire)

- Un contenu donn√© par l'utilisateur (obligatoire)

- Un auteur (obligatoire)

- S'il y a une image associ√©e son nom et ses labels

### üìöBase Dynamodb

Votre base Dynamodb aura comme cl√© de partition les utilisateurs, et comme cl√© de tri l'id des posts. Pour √©viter tout chevauchement entre les concepts, je valoriserai les groupes qui pr√©fixent ses deux attributs comme dans le TP 4. Exemple post = `POST#....`, user= `USER#....` 

Pour les attributs des objets que vous allez stocker, je vous conseiller de reprendre ceux du json des posts.

Voici un rappel des m√©thodes qui vous seront utiles :

```python
dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table(table_name)

data = table.put_item(
    Item={...})
    
data = table.delete_item(
    Key={'name' : 'jon',
    "lastname" : 'doe'}
)

table.update_item(
    Key={
        "name": "jon",
        "lastname": "doe"
    },
    UpdateExpression="SET address = :add, income = :inc",
    ExpressionAttributeValues={":add": address, ":inc": income},
)


data = table.scan()

data = table.query(
	KeyConditionExpression=Key('user').eq('jon' & Key("lastname".eq("doe")))
)
    

```

### ‚úÖLes retours des fonctions

Quand vous retournez des posts, pour que l'interface fonctionne correctement, un post doit √™tre un json avec les attributs suivants :

```json
 {
 	'user' : string,
    'id':'string'
	'title' : string,
    'body' : string,
	'image' : string //contient l'url de l'image,
    'label' : liste de string
 }
```

L'id, le titre et le body ne demandent pas d'explication. Image est une url vers l'image S3. Comme votre bucket sera priv√©, pour r√©cup√©rer une image il vous faut une url pr√©-sign√©e. Voici un exemple de code :

```python
def create_presigned_url(bucket_name, object_name, expiration=3600):
    """Generate a presigned URL to share an S3 object

    :param bucket_name: string
    :param object_name: string
    :param expiration: Time in seconds for the presigned URL to remain valid
    :return: Presigned URL as string. If error, returns None.
    """

    # Generate a presigned URL for the S3 object
    s3_client = boto3.client('s3')
    try:
        response = s3_client.generate_presigned_url('get_object',
                                                    Params={'Bucket': bucket_name,
                                                            'Key': object_name},
                                                    ExpiresIn=expiration)
    except ClientError as e:
        logging.error(e)
        return None

    # The response contains the presigned URL
    return response
```

Vous devrez g√©n√©rer vous m√™me cette url pour que l'image s'affiche.

Les labels ne seront r√©cup√©r√© qu'apr√®s la lab√©lisation de l'image

### ü§ñR√©cup√©rer le username

Pour simuler une vraie application, le nom de l'utilisateur sera, sauf mention contraire, r√©cup√©r√© dans le header de la requ√™te. En effet, les utilisateurs authentifi√©s envoient √† chaque requ√™te un jeton avec diverses informations, dont leur username. Dans notre cas pour simplifier, ce n'est pas un jeton qui va √™tre envoy√©, mais simplement le username dans un header de la requ√™te.

Le user name est le contenu de la variable `authorization`. 

Cela sera utile pour :

- poster une publication
- supprimer une publication

### üìÆPoster une publication

Voici le corps de la requ√™te pour poster une publication que vous enverra l'application Reactjs :

```js
 {
	'title' : string,
    'body' : string,
 }
```

Il vous faut mettre cela en base en calculant un id pour la publication. Le username est √† r√©cup√©rer dans le header comme dit ci-dessus.

Pour le retour attendu :

```python
data = table.put_item(...)
return data
```

### üß∫ Bucket S3 et d√©tection des labels

Dans le template fournit, un bucket S3 est d√©j√† d√©fini. La d√©tection des labels sera ex√©cut√©e d√©s qu'un objet sera upload√© sur S3. Pour faire cela, la lambda ne doit pas √™tre d√©clench√©e par une file  SQS comme dans un TP pr√©c√©dent, mais par la cr√©ation d'un objet sur S3. Voici un exemple pour vous aider :

```python
from cdktf_cdktf_provider_aws.s3_bucket_notification import S3BucketNotification, S3BucketNotificationLambdaFunction
from cdktf_cdktf_provider_aws.lambda_permission import LambdaPermission

bucket = S3Bucket(
    self, "bucket"
)
lambda_function = LambdaFunction(self,"lambda")
permission = LambdaPermission(
    self, "lambda_permission",
    action="lambda:InvokeFunction",
    statement_id="AllowExecutionFromS3Bucket",
    function_name=lambda_function.arn,
    principal="s3.amazonaws.com",
    source_arn=bucket.arn,
    source_account=account_id,
    depends_on=[lambda_function, bucket]
)

notification = S3BucketNotification(
    self, "notification",
    lambda_function=[S3BucketNotificationLambdaFunction(
        lambda_function_arn=lambda_function.arn,
        events=["s3:ObjectCreated:*"]
    )],
    bucket=bucket.id,
    depends_on=[permission]
)

```

Le code qui g√®re l'uploade des fichiers les met dans votre bucket √† l'adresse : `user/id_publication/image_name`. Comme votre fonction est d√©clench√©e par l'ajout dans objet dans un bucket, l'event va √™tre diff√©rent de celui d'une file SQS.

```json
{
  "Records": [
    {
      "eventVersion": "2.0",
      "eventSource": "aws:s3",
      "awsRegion": "us-east-1",
      "eventTime": "1970-01-01T00:00:00.000Z",
      "eventName": "ObjectCreated:Put",
      "userIdentity": {
        "principalId": "EXAMPLE"
      },
      "requestParameters": {
        "sourceIPAddress": "127.0.0.1"
      },
      "responseElements": {
        "x-amz-request-id": "EXAMPLE123456789",
        "x-amz-id-2": "EXAMPLE123/5678abcdefghijklambdaisawesome/mnopqrstuvwxyzABCDEFGH"
      },
      "s3": {
        "s3SchemaVersion": "1.0",
        "configurationId": "testConfigRule",
        "bucket": {
          "name": "example-bucket",
          "ownerIdentity": {
            "principalId": "EXAMPLE"
          },
          "arn": "arn:aws:s3:::example-bucket"
        },
        "object": {
          "key": "test%2Fkey",
          "size": 1024,
          "eTag": "0123456789abcdef0123456789abcdef",
          "sequencer": "0A1B2C3D4E5F678901"
        }
      }
    }
  ]
}
```

La partie qui vous int√©resse est la clef `s3`

```python
import boto3
import os
import logging
import json
from datetime import datetime
from urllib.parse import unquote_plus

table_name = os.getenv("TASKS_TABLE")
dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table(table_name)
reckognition = boto3.client('rekognition')
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    # Pour logger
    logger.info(json.dumps(event, indent=2))
    # R√©cup√©ration du nom du bucket
    bucket = event["Records"][0]["s3"]["bucket"]["name"]
    # R√©cup√©ration du nom de l'objet
    key = unquote_plus(event["Records"][0]["s3"]["object"]["key"])
	# extration de l'utilisateur et de l'id de la t√¢che
    user, task_id = key.split('/')[:2]
```

Il vous faut maintenant appeler le service Rekognition pour obtenir les labels de l'image. Voici un exemple de code et la [documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition/client/detect_labels.html) 

```python
# Appel au service, en passant l'image √† analyser (bucket et key)
# On souhaite au maximum 5 labels et uniquement les labels avec un taux de confiance > 0.75 
# Vous pouvez faire varier ces valeurs.
label_data = reckognition.detect_labels( 
        Image={
            "S3Object": {
                "Bucket": bucket,
                "Name": key
            }
        },
        MaxLabels=5,
        MinConfidence=0.75
    )
logger.info(f"Labels data : {label_data}")
# On extrait les labels du r√©sultat
labels = [label["Name"] for label in label_data["Labels"]]
logger.info(f"Labels detected : {labels}")
```

Puis il vous faut enfin ins√©rer les labels et la localisation de l'image dans s3 dans la base Dynamodb avec la m√©thode `update_item`. Vous stockerez en base le chemin de l'image dans la variable `key`.

### üìëR√©cup√©rer des posts

Cette fonctionnalit√© demande simplement d'aller r√©cup√©rer les donn√©es stock√©es dans la base. Attention n√©anmoins car un *query parameter* peut √™tre utilis√© pour r√©cup√©rer les posts d'un utilisateur en particulier. On peut soit appeler `base_url/posts` ou `base_url/posts?id_user=XXX`

```python
@app.get("/posts")
async def get_all_posts(id_user: Union[str, None] = None):
```

Votre code va devoir g√©rer les deux cas. Je vous conseille pour une meilleure lisibilit√© de faire deux m√©thodes qui seront appel√©es dans **le endpoint du webservice** en fonction du cas dans lequel vous vous trouvez. L'application web attend une r√©ponse qui contient une liste de postes, chaque poste ayant les informations suivantes : 

```js
 {
 	'user' : string,
	'title' : string,
    'body' : string,
	'image' : string //contient l'url de l'image,
    'label' : liste de string
 }
```

Pour obtenir l'url de l'image vous allez utiliser une url dite pr√©-sign√©e. En effet comme votre bucket est priv√©, pour rendre accessible les images, il faut cr√©er une url sp√©ciale. Voici le code pour g√©n√©rer cette url :

```python
bucket = os.getenv("S3_BUCKET")
s3_client = boto3.client('s3')

url = s3_client.generate_presigned_url(
    Params={
    "Bucket": bucket,
    "Key": object_name,
},
    ClientMethod='get_object'
)
```

Pour une publication donn√©e vous trouverez l'image dans le bucket de votre application au chemin suivant : `user/id_publication/image_name`

### ‚ùåSupprimer des posts

Enfin la suppression des posts va appeler la m√©thode `delete_item` pr√©sente dans le CM4. Cette fois-ci on va utiliser un *path parameter*.

```yaml
@app.delete("/posts/{post_id}")
async def get_post_user_id(post_id: int):
    # Doit retourner le r√©sultat de la requ√™te la table dynamodb
    return []
```

La subtilit√© de la suppression est que vous allez devoir supprimer la publication de la base de donn√©e, mais aussi supprimer son image dans le bucket S3 si elle en a une.

Pour le retour attendu :

```python
return table.delete_item()
```

### üíª Auto scaling group, Load Balancer, instances EC2, webservice

Cette architecture est g√©r√©e par le fichier `main_server.py`. Le script contient d√©j√† de quoi cr√©er les users data pour installer le code du webservice sur une instance EC2. Vous devez remplir la configuration des diff√©rents √©l√©ments (globalement la m√™me que dans le TP2). Les diff√©rences :

- Une seule machine de base au lieu de 2
- Le webservice √©coutera sur le port 8080 et pas 80 comme dans le TP. Vous allez devoir changer le port de du `LbTargetGroup`
- Pour que vos instances EC2 aient le droit d‚Äôinteragir avec S3 et DynamoDB il faut leur donner les droits. Cela passe par l'attribut iam_instance_profile de la classe `LaunchTemplate`. Cet attributs attend un dictionnaire en param√®tre `{"arn" : "arn_du_role"}`. Le r√¥le que vous passerez sera le m√™me r√¥le que pour la lambda. 
